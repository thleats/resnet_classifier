{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet_classifier_Lab_1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMDyohveAEaWZX0KIYINk6p"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UPg6TUxEw3n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5e960f1c-210b-4464-abb8-c26adf932b3d"
      },
      "source": [
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "from torch import optim, nn\n",
        "import os\n",
        "import sys\n",
        "from PIL import Image, ImageOps\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from os import path\n",
        "import urllib.request\n",
        "import pdb\n",
        "from torch.utils import data\n",
        "\n",
        "root = '/content/dataset'\n",
        "train_dataset = torchvision.datasets.CIFAR10(root, train=True, transform=None, target_transform=None, download=True)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root, train=False, transform=None, target_transform=None, download=True)\n",
        "\n",
        "class Dataset(data.Dataset):\n",
        "  'Characterizes a dataset for PyTorch'\n",
        "  def __init__(self,dataset):\n",
        "    'Initialization'\n",
        "    self.dataset=dataset\n",
        "  def __len__(self):\n",
        "    'Denotes the total number of samples'\n",
        "    return len(self.dataset)\n",
        "    #return 1024\n",
        "  def __getitem__(self, index):\n",
        "    'Generates one sample of data'\n",
        "    # Select sample\n",
        "    x,label = (self.dataset[index])\n",
        "\n",
        "    transform=transforms.Compose([transforms.ToTensor()])\n",
        "    im = transform(x)\n",
        "    return im, label\n",
        "\n",
        "train_loader = Dataset(train_dataset)\n",
        "test_loader = Dataset(test_dataset)\n",
        "\n",
        "batch_size=20\n",
        "params={'batch_size':batch_size,'shuffle':True}\n",
        "training_generator=data.DataLoader(train_loader,**params)\n",
        "test_generator=data.DataLoader(test_loader,**params)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnzvewZeNVYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for image,label in training_generator:\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1VrWhEaGA4I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "9557804a-3f1e-4543-e65c-ccf543fe688c"
      },
      "source": [
        "class resnet20(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(resnet20,self).__init__()\n",
        "    c=3\n",
        "    out = 10\n",
        "    channels=32\n",
        "    #####Create the first block\n",
        "    self.conv1=nn.Conv2d(c,channels,(3,3),padding=(1,1))\n",
        "    self.conv2=nn.Conv2d(channels,channels,(3,3),padding=(1,1))\n",
        "    self.conv3=nn.Conv2d(channels,channels,(3,3),padding=(1,1))\n",
        "    self.conv4=nn.Conv2d(channels,channels,(3,3),padding=(1,1))\n",
        "    self.conv5=nn.Conv2d(channels,channels,(3,3),padding=(1,1))\n",
        "    self.conv6=nn.Conv2d(channels,channels,(3,3),padding=(1,1))\n",
        "    self.conv7=nn.Conv2d(channels,channels,(3,3),padding=(1,1))\n",
        "\n",
        "\n",
        "\n",
        "    self.conv8=nn.Conv2d(channels,channels*2,(3,3),padding=(1,1))\n",
        "    self.conv9=nn.Conv2d(channels*2,channels*2,(3,3),padding=(1,1))\n",
        "    self.conv10=nn.Conv2d(channels*2,channels*2,(3,3),padding=(1,1))\n",
        "    self.conv11=nn.Conv2d(channels*2,channels*2,(3,3),padding=(1,1))\n",
        "    self.conv12=nn.Conv2d(channels*2,channels*2,(3,3),padding=(1,1))\n",
        "    self.conv13=nn.Conv2d(channels*2,channels*2,(3,3),padding=(1,1))\n",
        "    self.conv14=nn.Conv2d(channels*2,channels*2,(3,3),padding=(1,1))\n",
        "   \n",
        "    \n",
        "    \n",
        "    self.conv15=nn.Conv2d(channels*4,channels*4,(3,3),padding=(1,1))\n",
        "    self.conv16=nn.Conv2d(channels*4,channels*4,(3,3),padding=(1,1))\n",
        "    self.conv17=nn.Conv2d(channels*4,channels*4,(3,3),padding=(1,1))\n",
        "    self.conv18=nn.Conv2d(channels*8,channels*4,(3,3),padding=(1,1))\n",
        "    self.conv19=nn.Conv2d(channels*4,channels*4,(3,3),padding=(1,1))\n",
        "    self.conv20=nn.Conv2d(channels*4,channels*4,(3,3),padding=(1,1))\n",
        "    self.conv21=nn.Conv2d(channels*4,channels*4,(3,3),padding=(1,1))   \n",
        "\n",
        "    \n",
        "    self.bn1=nn.BatchNorm2d(channels)\n",
        "    self.activation = nn.ReLU()\n",
        "  \n",
        "  def forward(self,x):\n",
        "    n,c,h,w = x.size()\n",
        "    \n",
        "    o1=self.activation(self.conv1(x))\n",
        "    o2=self.activation(self.conv2(o1))\n",
        "    #print(o2.size())\n",
        "\n",
        "    size_tensor=o2.size()\n",
        "    variable=size_tensor[2]/2\n",
        "    \n",
        "\n",
        "    o3=m(o2)\n",
        "    #print(o3.size())\n",
        "    o4=self.activation(self.conv4(o3))\n",
        "    #print(o4.size())\n",
        "\n",
        "    o5=self.activation(self.conv5(o4))#o5 to o21\n",
        "    #print(o5.size())\n",
        "\n",
        "    \n",
        "    size_tensor=o5.size()\n",
        "    variable=size_tensor[2]/2\n",
        "    ##\n",
        "    m=nn.AdaptiveMaxPool2d(int(variable))\n",
        "    \n",
        "    o6=m(o5)\n",
        "    #print(o6.size())\n",
        "\n",
        "    o7=self.activation(self.conv7(o6))\n",
        "    #print(o7.size())\n",
        "\n",
        "    o8=self.activation(self.conv8(o7))#o8 to o18\n",
        "    #print(o8.size())\n",
        " \n",
        "    \n",
        "\n",
        "\n",
        "    o10=self.activation(self.conv10(o9))\n",
        "    #print(o10.size())\n",
        "\n",
        "    o11=self.activation(self.conv11(o10))#o11 to o15\n",
        "    #print(o11.size())\n",
        "\n",
        "\n",
        "    variable=size_tensor[2]/2\n",
        "    ##\n",
        " \n",
        "    o13=self.activation(self.conv13(o12))\n",
        "\n",
        "    o14=self.activation(self.conv14(o13))\n",
        "   \n",
        "    return o27.squeeze(2).squeeze(2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset CIFAR10\n",
              "    Number of datapoints: 50000\n",
              "    Root location: /content/dataset\n",
              "    Split: Train"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu9Aydn4K76b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpozjRKGLAp7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "60921038-a7f1-47f4-acd4-8bce7e6748cd"
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    }
  ]
}